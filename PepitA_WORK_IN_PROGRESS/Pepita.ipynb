{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to the target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        # Update accuracy\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and update accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1))\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_test_BP(model: torch.nn.Module,\n",
    "             train_dataloader: torch.utils.data.DataLoader,\n",
    "             test_dataloader: torch.utils.data.DataLoader,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             optimizer: torch.optim.Optimizer,\n",
    "             accuracy_fn,\n",
    "             lr: int,\n",
    "             epochs: int,\n",
    "             device: torch.device = device):\n",
    "    # Measure time\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr = lr)\n",
    "    time_start = timer()\n",
    "\n",
    "    # Train and test model\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n--------\")\n",
    "        train_step(model=model,\n",
    "                   data_loader=train_dataloader,\n",
    "                   loss_fn=loss_fn,\n",
    "                   optimizer=optimizer,\n",
    "                   accuracy_fn=accuracy_fn,\n",
    "                   device=device)\n",
    "        test_step(model=model,\n",
    "                  data_loader=test_dataloader,\n",
    "                  loss_fn=loss_fn,\n",
    "                  accuracy_fn=accuracy_fn,\n",
    "                  device=device)\n",
    "\n",
    "    time_end = timer()\n",
    "    total_train_time_model_2 = print_train_time(start=time_start,\n",
    "                                                end=time_end,\n",
    "                                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_PEPITA(model: torch.nn.Module,\n",
    "                      data_loader: torch.utils.data.DataLoader,\n",
    "                      loss_fn: torch.nn.Module,\n",
    "                      accuracy_fn,\n",
    "                      lr: int,\n",
    "                      device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "                # Send data to the target device\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                # 1. Forward pass\n",
    "                y_pred = model(X)\n",
    "\n",
    "                # 2. Calculate loss\n",
    "                loss = loss_fn(y_pred, y)\n",
    "                train_loss += loss\n",
    "\n",
    "                # Update accuracy\n",
    "                train_acc += accuracy_fn(y_true=y,\n",
    "                                            y_pred=y_pred.argmax(dim=1))\n",
    "                \n",
    "                target = F.one_hot(y, num_classes)\n",
    "                #print(target)\n",
    "                model.modulated_forward(X = X, \n",
    "                                        Y = y_pred,\n",
    "                                        target = target,\n",
    "                                        lr = lr)\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_test_PEPITA(model: torch.nn.Module,\n",
    "                 train_dataloader: torch.utils.data.DataLoader,\n",
    "                 test_dataloader: torch.utils.data.DataLoader,\n",
    "                 loss_fn: torch.nn.Module,\n",
    "                 accuracy_fn,\n",
    "                 lr: int,\n",
    "                 epochs: int,\n",
    "                 device: torch.device = device):\n",
    "    # Measure time\n",
    "    time_start = timer()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    num_classes = len(train_dataloader.dataset.classes)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n--------\")\n",
    "        train_step_PEPITA(model=model,\n",
    "                        data_loader=train_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        accuracy_fn=accuracy_fn,\n",
    "                        lr = lr,\n",
    "                        device=device)\n",
    "        test_step(model=model,\n",
    "                  data_loader=test_dataloader,\n",
    "                  loss_fn=loss_fn,\n",
    "                  accuracy_fn=accuracy_fn,\n",
    "                  device=device)\n",
    "\n",
    "    time_end = timer()\n",
    "    total_train_time_model_2 = print_train_time(start=time_start,\n",
    "                                                end=time_end,\n",
    "                                                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets \n",
    "\n",
    "def get_train_test_data(dataset_class, root):\n",
    "    train_data = dataset_class(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    "    )\n",
    "\n",
    "    test_data = dataset_class(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    "    )\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_some_images(train_data, class_names):\n",
    "    # Plot some images\n",
    "    torch.manual_seed(42)\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    rows, cols = 4, 4\n",
    "    for i in range(1, rows * cols + 1):\n",
    "        random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "        img, label = train_data[random_idx]\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        plt.title(class_names[label])\n",
    "        plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Get a dataset: FashionMNIST\n",
    "from torchvision import datasets \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def data(dataset_class):\n",
    "    root = 'data' #'/Users/alexcolagrande/Desktop/Python/BBpropTorch/PepitA_WORK_IN_PROGRESS/data'\n",
    "    train_data, test_data = get_train_test_data(dataset_class=dataset_class, root=root)\n",
    "\n",
    "    class_names = train_data.classes\n",
    "    class_to_idx = train_data.class_to_idx\n",
    "    # How many samples are there? \n",
    "    print(f\"train X: {len(train_data.data)}, train y: {len(train_data.targets)}, test X: {len(test_data.data)}, test y: {len(test_data.targets)}\")\n",
    "\n",
    "    plot_some_images(train_data=train_data, class_names=class_names)\n",
    "\n",
    "    ## Let's prepare the dataloader\n",
    "    # Setup the batch size\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    # Turn datasets into iterables (batches)\n",
    "    train_dataloader = DataLoader(dataset=train_data,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle = True)\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=test_data,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=False) # Better to not shuffle the test so every time we evaluate the model the batches are the same and not shuffled again and again\n",
    "\n",
    "    train_dataloader, test_dataloader\n",
    "    # Let's check out what we have created\n",
    "    print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "    print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "    # Check out what's inside the trainig dataloader\n",
    "    train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "    print(f\"Shape of the training batch: {train_features_batch.size()}, Shape of the training label batch: {train_labels_batch.size()}\")\n",
    "    n = train_features_batch.size()[1:].numel()     # input dimension\n",
    "    m = len(class_names)                            # output dimension\n",
    "    return train_dataloader, test_dataloader, class_names, class_to_idx, train_data, test_data, n, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SUPER_PEP(nn.Module):\n",
    "    \"\"\" \n",
    "        SUPER_PEP is an architecture implementing a modulated pass to be trained with PEPITA while being highly customizable:\n",
    "       -layers_dim: list containing the dimensions of ALL the layers i.e. [input_dim, hidden_dim1, hidden_dim2, ..., output_dim]\n",
    "       -bias: bool, do you want to use bias?\n",
    "       -F_std: float, the standard deviation of the F matrix\n",
    "       -vision: bool, do you want to flatten the input?\n",
    "       -F_norm: bool, do you want to normalize the \"projection\" matrix F?\n",
    "       -layer_norm: bool, do you want to normalize the output of every layer during the forward?\n",
    "       -error_norm: bool, do you want to normalize the error E before propagating it in the modulated pass?\n",
    "       -delta_norm: bool, do you want to normalize the delta_W before updating the weights?\n",
    "       -F_decay: float, the decay of the F matrix\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layers_dim: list, \n",
    "                 bias: bool=False,\n",
    "                 F_std: float=1,\n",
    "                 vision: bool=False,\n",
    "                 F_norm: bool=False,\n",
    "                 layer_norm: bool= False,\n",
    "                 error_norm: bool=False,\n",
    "                 delta_norm: bool=False,\n",
    "                 F_decay: float=1): \n",
    "        super().__init__()\n",
    "        self.vision = vision\n",
    "        self.F_norm = F_norm\n",
    "        self.layer_norm = layer_norm\n",
    "        self.error_norm = error_norm\n",
    "        self.delta_norm = delta_norm\n",
    "        self.F_decay = F_decay\n",
    "        \n",
    "        if self.vision:\n",
    "            self.flatten = nn.Flatten()\n",
    "                \n",
    "        self.nb_layers = len(layers_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(0, self.nb_layers - 1):\n",
    "            self.layers.append(nn.Linear(in_features=layers_dim[i], out_features=layers_dim[i+1], bias=bias))\n",
    "\n",
    "        self.F_T = F_std * torch.randn(size=(layers_dim[-1], layers_dim[0]))  \n",
    "        print(f\"F_norm: {LA.norm(self.F_T)}\")\n",
    "        if F_norm: \n",
    "            # Really important: with our inizialization (N(0,1)) the expected l_2 norm squared of F is input_dim * output_dim \n",
    "            self.F_T /= LA.norm(self.F_T) \n",
    "        self.activations = []\n",
    "        # Register hooks\n",
    "        for i in range(self.nb_layers-1):\n",
    "            self.layers[i].register_forward_hook(lambda module, input, output: self.save_activation(output))\n",
    "\n",
    "    def save_activation(self, output):\n",
    "        self.activations.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        if self.vision:\n",
    "            x = self.flatten(x)\n",
    "        for i in range(self.nb_layers-1):\n",
    "            x = self.layers[i](x)\n",
    "            if self.layer_norm:\n",
    "                x /= LA.matrix_norm(x)\n",
    "        return x\n",
    "    \n",
    "    def modulated_forward(self, X, Y, target, lr):\n",
    "        self.F_T *= self.F_decay\n",
    "        target = target.float()\n",
    "        E = Y - target \n",
    "        if self.error_norm:\n",
    "            E = E / LA.matrix_norm(E)\n",
    "        if self.vision:\n",
    "            X = self.flatten(X)\n",
    "    \n",
    "        #print(\"E\", E.shape, \"\\nF\", self.F.shape, \"\\nX\", X.shape)\n",
    "        X_mod = X - torch.mm(E, self.F_T)\n",
    "\n",
    "        H = self.activations # Forward activations\n",
    "        \n",
    "        modulated_forward = self.forward(X_mod)\n",
    "        H_mod = self.activations # Modulated activations\n",
    "        #print(\"H_1\", H[0].shape, \"H_1^mod\", H_mod[0].shape, \"\\nH_2\", H[1].shape, \"H_2^mod\", H_mod[1].shape, \"\\nE\", E.shape)\n",
    "\n",
    "        delta_W = torch.mm((H[0]-H_mod[0]).T,X_mod)\n",
    "        if self.delta_norm:\n",
    "            delta_W /= LA.matrix_norm(delta_W)\n",
    "        self.layers[0].weight -= lr * delta_W \n",
    "\n",
    "        for i in range(1, self.nb_layers-2): # I iterate over the \"number of functions - 1\" and number of functions = numbers of layers\n",
    "            delta_W = torch.mm((H[i]-H_mod[i]).T,H_mod[i])\n",
    "\n",
    "            if self.delta_norm:\n",
    "                delta_W /= LA.matrix_norm(delta_W)\n",
    "\n",
    "            #print(f\"i: {i}, delta_W = {delta_W.shape}, W: {self.layers[i].weight.shape}, H[{i}]: {H[i].shape}, H_mod[{i}]: {H_mod[i].shape}\")\n",
    "            self.layers[i].weight -= lr * delta_W \n",
    "        \n",
    "        delta_W_L = torch.mm(E.T,H_mod[-2])\n",
    "        if self.delta_norm:\n",
    "            delta_W_L /= LA.matrix_norm(delta_W_L)\n",
    "\n",
    "        self.layers[-1].weight -= lr * delta_W_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct PEPITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dpepita(nn.Module):\n",
    "    \"\"\" \n",
    "        Dpepita is a variant of PEPITA where the signal is backpropagated directed at every layer and there is no forward propagation of the modulated inputs while being higly customizable:\n",
    "       -layers_dim: list containing the dimensions of ALL the layers i.e. [input_dim, hidden_dim1, hidden_dim2, ..., output_dim]\n",
    "       -bias: bool, do you want to use bias?\n",
    "       -F_std: float, the standard deviation of the F matrix\n",
    "       -vision: bool, do you want to flatten the input?\n",
    "       -layer_norm: bool, do you want to normalize the output of every layer during the forward?\n",
    "       -error_norm: bool, do you want to normalize the error E before propagating it in the modulated pass?\n",
    "       -delta_norm: bool, do you want to normalize the delta_W before updating the weights?\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layers_dim: list, \n",
    "                 bias: bool=False,\n",
    "                 F_std: float=1,\n",
    "                 vision: bool=False,\n",
    "                 layer_norm: bool= False,\n",
    "                 error_norm: bool=False,\n",
    "                 delta_norm: bool=False): \n",
    "        super().__init__()\n",
    "        self.vision = vision\n",
    "        self.layer_norm = layer_norm\n",
    "        self.error_norm = error_norm\n",
    "        self.delta_norm = delta_norm\n",
    "        \n",
    "        if self.vision:\n",
    "            self.flatten = nn.Flatten()\n",
    "                \n",
    "        self.nb_layers = len(layers_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(0, self.nb_layers - 1):\n",
    "            self.layers.append(nn.Linear(in_features=layers_dim[i], out_features=layers_dim[i+1], bias=bias))\n",
    "\n",
    "        self.F_T = []\n",
    "        for i in range(self.nb_layers - 1):\n",
    "            self.F_T.append(F_std * torch.randn(size=(layers_dim[-1], layers_dim[i]))) \n",
    "\n",
    "        self.activations = []\n",
    "        # Register hooks\n",
    "        for i in range(self.nb_layers-1):\n",
    "            self.layers[i].register_forward_hook(lambda module, input, output: self.save_activation(output))\n",
    "\n",
    "    def save_activation(self, output):\n",
    "        self.activations.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        if self.vision:\n",
    "            x = self.flatten(x)\n",
    "        for i in range(self.nb_layers-1):\n",
    "            x = self.layers[i](x)\n",
    "            if self.layer_norm:\n",
    "                x /= torch.linalg_matrix_norm(x)\n",
    "        return x\n",
    "    \n",
    "    def modulated_forward(self, X, Y, target, lr):\n",
    "        target = target.float()\n",
    "        E = Y - target \n",
    "        if self.error_norm:\n",
    "            E = E / torch.norm(E)\n",
    "        if self.vision:\n",
    "            X = self.flatten(X)\n",
    "    \n",
    "        #print(\"E\", E.shape, \"\\nF\", self.F.shape, \"\\nX\", X.shape)\n",
    "        X_mod = X - torch.mm(E, self.F_T)\n",
    "\n",
    "        H = self.activations # Forward activations\n",
    "        \n",
    "        #modulated_forward = self.forward(X_mod)\n",
    "        #H_mod = self.activations # Modulated activations\n",
    "        #print(\"H_1\", H[0].shape, \"H_1^mod\", H_mod[0].shape, \"\\nH_2\", H[1].shape, \"H_2^mod\", H_mod[1].shape, \"\\nE\", E.shape)\n",
    "        h_mod = H[i]\n",
    "\n",
    "        delta_W = torch.mm((H[0]-H_mod[0]).T,X_mod)\n",
    "\n",
    "        for i in range(1, self.nb_layers-2): # I iterate over the \"number of functions - 1\" and number of functions = numbers of layers\n",
    "            delta_W = torch.mm((H[i]-H_mod[i]).T,H_mod[i])\n",
    "\n",
    "            if self.delta_norm:\n",
    "                delta_W /= torch.linalg_matrix_norm(delta_W)\n",
    "\n",
    "            #print(f\"i: {i}, delta_W = {delta_W.shape}, W: {self.layers[i].weight.shape}, H[{i}]: {H[i].shape}, H_mod[{i}]: {H_mod[i].shape}\")\n",
    "            self.layers[i].weight -= lr * delta_W \n",
    "        \n",
    "        for i in range(self.nb_layers-2):\n",
    "            delta_W = torch.mm((H[i]-H_mod[i]).T, )\n",
    "            \n",
    "        \n",
    "        delta_W_L = torch.mm(E.T,H_mod[-2])\n",
    "        if self.delta_norm:\n",
    "            delta_W_L /= torch.linalg_matrix_norm(delta_W_L)\n",
    "\n",
    "        self.layers[-1].weight -= lr * delta_W_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target PEPITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TARGET_PEP(nn.Module):\n",
    "    \"\"\" \n",
    "        TARGET_PEP is what PEPITA wants to be while being highly customizable:\n",
    "       -layers_dim: list containing the dimensions of ALL the layers i.e. [input_dim, hidden_dim1, hidden_dim2, ..., output_dim]\n",
    "       -bias: bool, do you want to use bias?\n",
    "       -F_std: float, the standard deviation of the F matrix\n",
    "       -vision: bool, do you want to flatten the input?\n",
    "       -F_norm: bool, do you want to normalize the \"projection\" matrix F?\n",
    "       -layer_norm: bool, do you want to normalize the output of every layer during the forward?\n",
    "       -error_norm: bool, do you want to normalize the error E before propagating it in the modulated pass?\n",
    "       -delta_norm: bool, do you want to normalize the delta_W before updating the weights?\n",
    "       -F_decay: float, the decay of the F matrix\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layers_dim: list, \n",
    "                 bias: bool=False,\n",
    "                 F_std: float=1,\n",
    "                 vision: bool=False,\n",
    "                 F_norm: bool=False,\n",
    "                 layer_norm: bool= False,\n",
    "                 error_norm: bool=False,\n",
    "                 delta_norm: bool=False,\n",
    "                 F_decay: float=1): \n",
    "        super().__init__()\n",
    "        self.vision = vision\n",
    "        self.F_norm = F_norm\n",
    "        self.layer_norm = layer_norm\n",
    "        self.error_norm = error_norm\n",
    "        self.delta_norm = delta_norm\n",
    "        self.F_decay = F_decay\n",
    "        \n",
    "        if self.vision:\n",
    "            self.flatten = nn.Flatten()\n",
    "                \n",
    "        self.nb_layers = len(layers_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(0, self.nb_layers - 1):\n",
    "            self.layers.append(nn.Linear(in_features=layers_dim[i], out_features=layers_dim[i+1], bias=bias))\n",
    "\n",
    "        ############################################# WE CHANGE JUST THIS PART ###############################################\n",
    "        self.F_T = self.layers[0].weight.clone()\n",
    "        for i  in range(1, self.nb_layers - 1):\n",
    "            #print(f\"F_T: {self.F_T.shape}, W: {self.layers[i].weight.shape}\")\n",
    "            self.F_T = torch.mm(self.layers[i].weight.clone(), self.F_T)\n",
    "        self.F_T = self.F_T\n",
    "        print(f\"F_norm: {LA.norm(self.F_T)}\")\n",
    "        if F_norm: \n",
    "            # Really important: with our inizialization (N(0,1)) the expected l_2 norm squared of F is input_dim * output_dim \n",
    "            self.F_T /= LA.norm(self.F_T) \n",
    "        ######################################################################################################################\n",
    "        self.activations = []\n",
    "        # Register hooks\n",
    "        for i in range(self.nb_layers-1):\n",
    "            self.layers[i].register_forward_hook(lambda module, input, output: self.save_activation(output))\n",
    "\n",
    "    def save_activation(self, output):\n",
    "        self.activations.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        if self.vision:\n",
    "            x = self.flatten(x)\n",
    "        for i in range(self.nb_layers-1):\n",
    "            x = self.layers[i](x)\n",
    "            if self.layer_norm:\n",
    "                x /= LA.matrix_norm(x)\n",
    "        return x\n",
    "    \n",
    "    def modulated_forward(self, X, Y, target, lr):\n",
    "        self.F_T *= self.F_decay\n",
    "        target = target.float()\n",
    "        E = Y - target \n",
    "        if self.error_norm:\n",
    "            E = E / LA.matrix_norm(E)\n",
    "        if self.vision:\n",
    "            X = self.flatten(X)\n",
    "    \n",
    "        #print(\"E\", E.shape, \"\\nF\", self.F.shape, \"\\nX\", X.shape)\n",
    "        X_mod = X - torch.mm(E, self.F_T)\n",
    "\n",
    "        H = self.activations # Forward activations\n",
    "        \n",
    "        modulated_forward = self.forward(X_mod)\n",
    "        H_mod = self.activations # Modulated activations\n",
    "        #print(\"H_1\", H[0].shape, \"H_1^mod\", H_mod[0].shape, \"\\nH_2\", H[1].shape, \"H_2^mod\", H_mod[1].shape, \"\\nE\", E.shape)\n",
    "\n",
    "        delta_W = torch.mm((H[0]-H_mod[0]).T,X_mod)\n",
    "        if self.delta_norm:\n",
    "            delta_W /= LA.matrix_norm(delta_W)\n",
    "        self.layers[0].weight -= lr * delta_W \n",
    "\n",
    "        for i in range(1, self.nb_layers-2): # I iterate over the \"number of functions - 1\" and number of functions = numbers of layers\n",
    "            delta_W = torch.mm((H[i]-H_mod[i]).T,H_mod[i])\n",
    "\n",
    "            if self.delta_norm:\n",
    "                delta_W /= LA.matrix_norm(delta_W)\n",
    "\n",
    "            #print(f\"i: {i}, delta_W = {delta_W.shape}, W: {self.layers[i].weight.shape}, H[{i}]: {H[i].shape}, H_mod[{i}]: {H_mod[i].shape}\")\n",
    "            self.layers[i].weight -= lr * delta_W \n",
    "        \n",
    "        delta_W_L = torch.mm(E.T,H_mod[-2])\n",
    "        if self.delta_norm:\n",
    "            delta_W_L /= LA.matrix_norm(delta_W_L)\n",
    "\n",
    "        self.layers[-1].weight -= lr * delta_W_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names, class_to_idx, train_data, test_data, n, num_classes = data(datasets.MNIST)\n",
    "m = num_classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "#torch.cuda_manual_seed(42)\n",
    "MYFIRSTsuper_pep = SUPER_PEP(layers_dim= [n] + [1024] * 1 + [m],\n",
    "                             bias=False,\n",
    "                             F_std=0.01,\n",
    "                             vision=True,\n",
    "                             F_norm=False,\n",
    "                             layer_norm=False,\n",
    "                             error_norm=False,\n",
    "                             delta_norm=False,\n",
    "                             F_decay=0.9)\n",
    "MYFIRSTsuper_pep.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the forward works\n",
    "torch.manual_seed(42)\n",
    "dummy_x = torch.rand(size = (3, 1, 28, 28))\n",
    "MYFIRSTsuper_pep(dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize TARGET_PEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "#torch.cuda_manual_seed(42)\n",
    "Tpep = TARGET_PEP(layers_dim= [n] + [1024] * 15 + [m],\n",
    "                             bias=False,\n",
    "                             F_std=1,\n",
    "                             vision=True,\n",
    "                             F_norm=False,\n",
    "                             layer_norm=False,\n",
    "                             error_norm=False,\n",
    "                             delta_norm=False,\n",
    "                             F_decay=1)\n",
    "Tpep.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the forward works\n",
    "torch.manual_seed(42)\n",
    "dummy_x = torch.rand(size = (3, 1, 28, 28))\n",
    "Tpep(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model\n",
    "model = Tpep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy_fn = accuracy_fn\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr = lr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test with PEPITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_PEPITA(model = model,\n",
    "                 train_dataloader = train_dataloader,\n",
    "                 test_dataloader = test_dataloader,\n",
    "                 loss_fn = loss_fn,\n",
    "                 accuracy_fn = accuracy_fn,\n",
    "                 lr = lr,\n",
    "                 epochs = epochs,\n",
    "                 device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test with BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_BP(model = model,\n",
    "             train_dataloader = train_dataloader,\n",
    "             test_dataloader = test_dataloader,\n",
    "             loss_fn = loss_fn,\n",
    "             optimizer = optimizer,\n",
    "             accuracy_fn = accuracy_fn,\n",
    "             lr = lr,\n",
    "             epochs = epochs,\n",
    "             device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36.16 32.98 32.33 31.81 31.40 30.91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
